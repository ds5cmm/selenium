{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready For Wide-N-Deep Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/gsshop/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow version 1.10.1\n"
     ]
    }
   ],
   "source": [
    "# Set to INFO for tracking training\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "print(\"Using Tensorflow version %s\" % (tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'gender', 'native_country']\n",
    "\n",
    "# columns of the input csv\n",
    "COLUMNS = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "           'relationship', 'race', 'gender', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income_bracket']\n",
    "\n",
    "# feature columns for input into the model\n",
    "FEATURE_COLUMNS = ['age', 'workclass', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race',\n",
    "                  'gender', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Feature Description\n",
    "\n",
    "age :나이\n",
    "workclass : 소속 근무지 고용주의 유형\n",
    "fnlwgt : final weight, 인구 조사 샘플링 예측 지수. sample 데이터의 weight를 나타냄.\n",
    "education : 교육 수준\n",
    "education_num : 교육 수준을 numerical하게 표현\n",
    "marital_status : 결혼 상태\n",
    "occupation : 직종\n",
    "relationship : 거주가족관계\n",
    "race : 인종\n",
    "gender : 성별\n",
    "capital_gain : 수입 기록\n",
    "capital_loss : 지출 기록\n",
    "hours_per_week : 주당 근무시간\n",
    "native_country : 모국\n",
    "income_bracket : 소득 계층\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('adult.data.csv', header=None, names=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race   gender  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country income_bracket  \n",
       "0          2174             0              40   United-States          <=50K  \n",
       "1             0             0              13   United-States          <=50K  \n",
       "2             0             0              40   United-States          <=50K  \n",
       "3             0             0              40   United-States          <=50K  \n",
       "4             0             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
       "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours_per_week  \n",
       "count    32561.000000  \n",
       "mean        40.437456  \n",
       "std         12.347429  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.076646</td>\n",
       "      <td>0.036527</td>\n",
       "      <td>0.077674</td>\n",
       "      <td>0.057775</td>\n",
       "      <td>0.068756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>-0.076646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043195</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>-0.010252</td>\n",
       "      <td>-0.018768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>0.036527</td>\n",
       "      <td>-0.043195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122630</td>\n",
       "      <td>0.079923</td>\n",
       "      <td>0.148123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>0.077674</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.122630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031615</td>\n",
       "      <td>0.078409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>0.057775</td>\n",
       "      <td>-0.010252</td>\n",
       "      <td>0.079923</td>\n",
       "      <td>-0.031615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>0.068756</td>\n",
       "      <td>-0.018768</td>\n",
       "      <td>0.148123</td>\n",
       "      <td>0.078409</td>\n",
       "      <td>0.054256</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "age             1.000000 -0.076646       0.036527      0.077674      0.057775   \n",
       "fnlwgt         -0.076646  1.000000      -0.043195      0.000432     -0.010252   \n",
       "education_num   0.036527 -0.043195       1.000000      0.122630      0.079923   \n",
       "capital_gain    0.077674  0.000432       0.122630      1.000000     -0.031615   \n",
       "capital_loss    0.057775 -0.010252       0.079923     -0.031615      1.000000   \n",
       "hours_per_week  0.068756 -0.018768       0.148123      0.078409      0.054256   \n",
       "\n",
       "                hours_per_week  \n",
       "age                   0.068756  \n",
       "fnlwgt               -0.018768  \n",
       "education_num         0.148123  \n",
       "capital_gain          0.078409  \n",
       "capital_loss          0.054256  \n",
       "hours_per_week        1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr() # numerical features correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input file parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example:\n",
    "\n",
    "{ \n",
    "\n",
    "  'age':            [ 39, 50, 38, 53, 28, … ], \n",
    "  \n",
    "  'marital_status': [ 'Married-civ-spouse', 'Never-married', 'Widowed', 'Widowed' … ],\n",
    "  \n",
    "   ...\n",
    "   \n",
    "  'gender':           ['Male', 'Female', 'Male', 'Male', 'Female',, … ], \n",
    "  \n",
    "} , \n",
    "\n",
    "[ 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input function configured\n"
     ]
    }
   ],
   "source": [
    "# BATCH_SIZE = 40\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "def generate_input_fn(filename, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Function to generate input data by preprocessing\n",
    "    input is filename, output is data for traing, test\n",
    "    \"\"\"\n",
    "    def _input_fn():\n",
    "        filename_queue = tf.train.string_input_producer([filename])\n",
    "        reader = tf.TextLineReader()\n",
    "        \n",
    "        # reads out batch size number of lines : file queue로, 데이터를 batch로 read\n",
    "        key, rows = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "        \n",
    "        # record_defaults should match the datatypes of each respectively : 각 column별 default값 지정\n",
    "        record_defaults = [[0], [\" \"], [0], [\" \"], [0],\n",
    "                          [\" \"], [\" \"], [\" \"], [\" \"], [\" \"],\n",
    "                          [0], [0], [0], [\" \"], [\" \"]]\n",
    "        \n",
    "        # add new axis == add new dimension\n",
    "        # ex) a = np.array([1, 2, 3, 4, 5])\n",
    "        # a = a[:, np.newaxis]\n",
    "        # array([[1],\n",
    "        #       [2],\n",
    "        #       [3],\n",
    "        #       [4],\n",
    "        #       [5]])\n",
    "        rows = rows[:, np.newaxis]\n",
    "        \n",
    "        # Decode csv data that was just read out : file queue, reader로 읽어들이는 데이터는 인코딩된 데이터이므로 디코딩이 필요함.\n",
    "        columns = tf.decode_csv(rows, record_defaults=record_defaults)\n",
    "        print(columns)\n",
    "        \n",
    "        # feature mapping to dictionary\n",
    "        all_columns = dict(zip(COLUMNS, columns))\n",
    "        \n",
    "        # income_bracket is y_label in our data\n",
    "        income_bracket = all_columns.pop('income_bracket')\n",
    "        \n",
    "        # remove the fnlwgt key, which is not used. --> 의미없는 데이터\n",
    "        all_columns.pop('fnlwgt', 'fnlwgt key not found')\n",
    "        \n",
    "        # the remaining columns are our features\n",
    "        features = all_columns\n",
    "        \n",
    "        # convert y label as binary (>50K is 1, <=50K is 0)\n",
    "        labels = tf.to_int32(tf.equal(income_bracket, \" >50K\"))\n",
    "        \n",
    "        print(features, labels)\n",
    "        \n",
    "        return features, labels\n",
    "    return _input_fn\n",
    "\n",
    "print('input function configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Feature Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wide n deep 학습법은 일반적으로 sparse한 입력 feature를 가진(1) 데이터의 회귀 및 분류문제에 적합하다.\n",
    "- 학습에 앞서, sparse feature의 특징을 가진 데이터를 인코딩한다.\n",
    "\n",
    "(1) : 많은 수의 카테고리적 특징을 가진, 길이가 긴 one-hot 인코딩을 해야하는 카테고리 피처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse columns configured\n"
     ]
    }
   ],
   "source": [
    "# The layers module contains many utilities for creating feature columns.\n",
    "from tensorflow.contrib import layers\n",
    "\n",
    "# Sparse columns : unique count가 5개 이하인 피처는 keys로 sparse mapping\n",
    "gender = layers.sparse_column_with_keys(column_name='gender',\n",
    "                                       keys=['female', 'male'])\n",
    "race = layers.sparse_column_with_keys(column_name='race',\n",
    "                                       keys=[\"Amer-Indian-Eskimo\",\n",
    "                                            \"Asian-Pac-Islander\",\n",
    "                                            \"Black\", \"Other\",\n",
    "                                            \"White\"])\n",
    "\n",
    "# 5개 초과는 hash bucket으로 매핑\n",
    "education = layers.sparse_column_with_hash_bucket(\"education\", hash_bucket_size=1000)\n",
    "marital_status = layers.sparse_column_with_hash_bucket(\"marital_status\", hash_bucket_size=100)\n",
    "relationship = layers.sparse_column_with_hash_bucket(\"relationship\", hash_bucket_size=100)\n",
    "workclass = layers.sparse_column_with_hash_bucket(\"workclass\", hash_bucket_size=100)\n",
    "occupation = layers.sparse_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)\n",
    "native_country = layers.sparse_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)\n",
    "\n",
    "print('sparse columns configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous columns configured\n"
     ]
    }
   ],
   "source": [
    "# Continuous base columns.\n",
    "age = layers.real_valued_column(\"age\")\n",
    "education_num = layers.real_valued_column(\"education_num\")\n",
    "capital_gain = layers.real_valued_column(\"capital_gain\")\n",
    "capital_loss = layers.real_valued_column(\"capital_loss\")\n",
    "hours_per_week = layers.real_valued_column(\"hours_per_week\")\n",
    "\n",
    "print('continuous columns configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transformations\n",
    "- bucketizing : numerical 데이터를 categorical 데이터로 변환하는것. feature crossing을 위해서 bucketizing 한다.\n",
    "- feature crossing : 모델 학습 시, 특정 column들을 pairing 하는것을 말한다. 독립적인 피처로 존재하는 것 보다 합쳐진게 더 의미가 있는 경우에 사용한다.\n",
    "- wide n deep 논문에서의 feature cross는 이것을 의미한다.\n",
    "\n",
    "For example, crossing education and occupation would enable the model to learn about:\n",
    "\n",
    "education=\"Bachelors\" AND occupation=\"Exec-managerial\"\n",
    "\n",
    "or perhaps\n",
    "\n",
    "education=\"Bachelors\" AND occupation=\"Craft-repair\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformations complete\n"
     ]
    }
   ],
   "source": [
    "# Transformations\n",
    "\n",
    "# age feature bucketizing\n",
    "age_buckets = layers.bucketized_column(\n",
    "    age, boundaries=[ 18, 25, 30, 35, 40, 45, 50, 55, 60, 65 ])\n",
    "\n",
    "# education X occupation Crossing : 교육 수준과 직종을 크로스\n",
    "education_occupation = layers.crossed_column(\n",
    "    [education, occupation], hash_bucket_size=int(1e4))\n",
    "\n",
    "# 3개를 크로스\n",
    "age_race_occupation = layers.crossed_column(\n",
    "    [age_buckets, race, occupation], hash_bucket_size=int(1e6))\n",
    "\n",
    "# 2개를 크로스\n",
    "country_occupation = layers.crossed_column(\n",
    "    [native_country, occupation], hash_bucket_size=int(1e4))\n",
    "\n",
    "print('Transformations complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping Wide Columns, Deep Columns\n",
    "- wide columns are very sparse : all hashed columns, crossed columns\n",
    "- deep columns are automatically crossing or regularization or something like that.\n",
    "- deep columns 에서 embedding_column 레이어로 sparse한 feature들을 8차원으로 임베딩함(학습의 일부)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "WARNING:tensorflow:The default stddev value of initializer will change from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" after 2017/02/25.\n",
      "wide and deep columns configured\n"
     ]
    }
   ],
   "source": [
    "# wide columns\n",
    "wide_columns = [gender, race, native_country,\n",
    "      education, occupation, workclass,\n",
    "      marital_status, relationship,\n",
    "      age_buckets, education_occupation,\n",
    "      age_race_occupation, country_occupation]\n",
    "\n",
    "# deep columns\n",
    "deep_columns = [\n",
    "  layers.embedding_column(workclass, dimension=8),\n",
    "  layers.embedding_column(education, dimension=8),\n",
    "  layers.embedding_column(marital_status, dimension=8),\n",
    "  layers.embedding_column(gender, dimension=8),\n",
    "  layers.embedding_column(relationship, dimension=8),\n",
    "  layers.embedding_column(race, dimension=8),\n",
    "  layers.embedding_column(native_country, dimension=8),\n",
    "  layers.embedding_column(occupation, dimension=8),\n",
    "  age,\n",
    "  education_num,\n",
    "  capital_gain,\n",
    "  capital_loss,\n",
    "  hours_per_week,\n",
    "]\n",
    "\n",
    "print('wide and deep columns configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Wide Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_classification_model():\n",
    "    model_dir = 'models/model_' + 'linear' + str(int(time.time()))\n",
    "    print(\"model directory = %s\" % model_dir)\n",
    "    \n",
    "    # define classifier\n",
    "    model = learn.LinearClassifier(\n",
    "#         model_dir=model_dir,\n",
    "        feature_columns=wide_columns\n",
    "    )\n",
    "    \n",
    "    # set dataset\n",
    "    train_dataset = str(\"adult.data.csv\")\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(input_fn=generate_input_fn(train_dataset, BATCH_SIZE), steps=1000)\n",
    "    print(\"training finish!\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model directory = models/model_linear1544058692\n",
      "WARNING:tensorflow:From /anaconda3/envs/gsshop/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py:469: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From /anaconda3/envs/gsshop/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1179: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From /anaconda3/envs/gsshop/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/lc/lqvc1rb14k5088l07s6hzw8w0000gn/T/tmpj8t85t51\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11f62c470>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/var/folders/lc/lqvc1rb14k5088l07s6hzw8w0000gn/T/tmpj8t85t51'}\n",
      "[<tf.Tensor 'DecodeCSV:0' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:1' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:2' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:3' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:4' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:5' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:6' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:7' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:8' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:9' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:10' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:11' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:12' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:13' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:14' shape=(?, 1) dtype=string>]\n",
      "{'age': <tf.Tensor 'DecodeCSV:0' shape=(?, 1) dtype=int32>, 'workclass': <tf.Tensor 'DecodeCSV:1' shape=(?, 1) dtype=string>, 'education': <tf.Tensor 'DecodeCSV:3' shape=(?, 1) dtype=string>, 'education_num': <tf.Tensor 'DecodeCSV:4' shape=(?, 1) dtype=int32>, 'marital_status': <tf.Tensor 'DecodeCSV:5' shape=(?, 1) dtype=string>, 'occupation': <tf.Tensor 'DecodeCSV:6' shape=(?, 1) dtype=string>, 'relationship': <tf.Tensor 'DecodeCSV:7' shape=(?, 1) dtype=string>, 'race': <tf.Tensor 'DecodeCSV:8' shape=(?, 1) dtype=string>, 'gender': <tf.Tensor 'DecodeCSV:9' shape=(?, 1) dtype=string>, 'capital_gain': <tf.Tensor 'DecodeCSV:10' shape=(?, 1) dtype=int32>, 'capital_loss': <tf.Tensor 'DecodeCSV:11' shape=(?, 1) dtype=int32>, 'hours_per_week': <tf.Tensor 'DecodeCSV:12' shape=(?, 1) dtype=int32>, 'native_country': <tf.Tensor 'DecodeCSV:13' shape=(?, 1) dtype=string>} Tensor(\"ToInt32:0\", shape=(?, 1), dtype=int32)\n",
      "WARNING:tensorflow:From /anaconda3/envs/gsshop/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py:2388: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:From /anaconda3/envs/gsshop/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/lc/lqvc1rb14k5088l07s6hzw8w0000gn/T/tmpj8t85t51/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6931472, step = 1\n",
      "INFO:tensorflow:global_step/sec: 144.895\n",
      "INFO:tensorflow:loss = 0.9142356, step = 101 (0.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 548.98\n",
      "INFO:tensorflow:loss = 0.21456268, step = 201 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.228\n",
      "INFO:tensorflow:loss = 1.7947366, step = 301 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.513\n",
      "INFO:tensorflow:loss = 0.004964136, step = 401 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 555.411\n",
      "INFO:tensorflow:loss = 0.016873376, step = 501 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 562.879\n",
      "INFO:tensorflow:loss = 0.09005361, step = 601 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.604\n",
      "INFO:tensorflow:loss = 0.19122094, step = 701 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.076\n",
      "INFO:tensorflow:loss = 0.1207708, step = 801 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 578.025\n",
      "INFO:tensorflow:loss = 0.27007145, step = 901 (0.173 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/lc/lqvc1rb14k5088l07s6hzw8w0000gn/T/tmpj8t85t51/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.10364893.\n",
      "training finish!\n",
      "CPU times: user 9.09 s, sys: 1.69 s, total: 10.8 s\n",
      "Wall time: 7.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1 = wide_classification_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_classification_model():\n",
    "    model_dir = 'models/model_' + 'deep' + str(int(time.time()))\n",
    "    print(\"model directory = %s\" % model_dir)\n",
    "    \n",
    "    # define classifier\n",
    "    model = learn.DNNClassifier(\n",
    "        model_dir=model_dir,\n",
    "        feature_columns=deep_columns,\n",
    "        hidden_units=[100,70,50,25]\n",
    "    )\n",
    "    \n",
    "    # set dataset\n",
    "    train_dataset = str(\"adult.data.csv\")\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(input_fn=generate_input_fn(train_dataset, BATCH_SIZE), steps=1000)\n",
    "    print(\"training finish!\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model directory = models/model_deep1544058705\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1242924e0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'models/model_deep1544058705'}\n",
      "[<tf.Tensor 'DecodeCSV:0' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:1' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:2' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:3' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:4' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:5' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:6' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:7' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:8' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:9' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:10' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:11' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:12' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:13' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:14' shape=(?, 1) dtype=string>]\n",
      "{'age': <tf.Tensor 'DecodeCSV:0' shape=(?, 1) dtype=int32>, 'workclass': <tf.Tensor 'DecodeCSV:1' shape=(?, 1) dtype=string>, 'education': <tf.Tensor 'DecodeCSV:3' shape=(?, 1) dtype=string>, 'education_num': <tf.Tensor 'DecodeCSV:4' shape=(?, 1) dtype=int32>, 'marital_status': <tf.Tensor 'DecodeCSV:5' shape=(?, 1) dtype=string>, 'occupation': <tf.Tensor 'DecodeCSV:6' shape=(?, 1) dtype=string>, 'relationship': <tf.Tensor 'DecodeCSV:7' shape=(?, 1) dtype=string>, 'race': <tf.Tensor 'DecodeCSV:8' shape=(?, 1) dtype=string>, 'gender': <tf.Tensor 'DecodeCSV:9' shape=(?, 1) dtype=string>, 'capital_gain': <tf.Tensor 'DecodeCSV:10' shape=(?, 1) dtype=int32>, 'capital_loss': <tf.Tensor 'DecodeCSV:11' shape=(?, 1) dtype=int32>, 'hours_per_week': <tf.Tensor 'DecodeCSV:12' shape=(?, 1) dtype=int32>, 'native_country': <tf.Tensor 'DecodeCSV:13' shape=(?, 1) dtype=string>} Tensor(\"ToInt32:0\", shape=(?, 1), dtype=int32)\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into models/model_deep1544058705/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.5514307e-35, step = 1\n",
      "INFO:tensorflow:global_step/sec: 141.805\n",
      "INFO:tensorflow:loss = 1.2609121, step = 101 (0.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.036\n",
      "INFO:tensorflow:loss = 47.928257, step = 201 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.725\n",
      "INFO:tensorflow:loss = 0.0, step = 301 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.785\n",
      "INFO:tensorflow:loss = 0.2852287, step = 401 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.343\n",
      "INFO:tensorflow:loss = 0.06380919, step = 501 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 580.464\n",
      "INFO:tensorflow:loss = 0.2261208, step = 601 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.959\n",
      "INFO:tensorflow:loss = 0.26789442, step = 701 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.081\n",
      "INFO:tensorflow:loss = 0.36804944, step = 801 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.307\n",
      "INFO:tensorflow:loss = 0.29989424, step = 901 (0.177 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into models/model_deep1544058705/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.2473543e-37.\n",
      "training finish!\n",
      "CPU times: user 8.46 s, sys: 1.5 s, total: 9.96 s\n",
      "Wall time: 6.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model2 = deep_classification_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Wide & Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_n_deep_classification_model():\n",
    "    model_dir = 'models/model_' + 'widendeep' + str(int(time.time()))\n",
    "    print(\"model directory = %s\" % model_dir)\n",
    "    \n",
    "    # define classifier\n",
    "    model = learn.DNNLinearCombinedClassifier(\n",
    "        model_dir=model_dir,\n",
    "        linear_feature_columns=wide_columns,\n",
    "        dnn_feature_columns=deep_columns,\n",
    "        dnn_hidden_units=[100,70,50,25]\n",
    "    )\n",
    "    \n",
    "    # set dataset\n",
    "    train_dataset = str(\"adult.data.csv\")\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(input_fn=generate_input_fn(train_dataset, BATCH_SIZE), steps=1000)\n",
    "    print(\"training finish!\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model directory = models/model_widendeep1544058712\n",
      "WARNING:tensorflow:From <ipython-input-19-e66907ffe7c4>:10: calling DNNLinearCombinedClassifier.__init__ (from tensorflow.contrib.learn.python.learn.estimators.dnn_linear_combined) with fix_global_step_increment_bug=False is deprecated and will be removed after 2017-04-15.\n",
      "Instructions for updating:\n",
      "Please set fix_global_step_increment_bug=True and update training steps in your pipeline. See pydoc for details.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x127ea3fd0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'models/model_widendeep1544058712'}\n",
      "[<tf.Tensor 'DecodeCSV:0' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:1' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:2' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:3' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:4' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:5' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:6' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:7' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:8' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:9' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:10' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:11' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:12' shape=(?, 1) dtype=int32>, <tf.Tensor 'DecodeCSV:13' shape=(?, 1) dtype=string>, <tf.Tensor 'DecodeCSV:14' shape=(?, 1) dtype=string>]\n",
      "{'age': <tf.Tensor 'DecodeCSV:0' shape=(?, 1) dtype=int32>, 'workclass': <tf.Tensor 'DecodeCSV:1' shape=(?, 1) dtype=string>, 'education': <tf.Tensor 'DecodeCSV:3' shape=(?, 1) dtype=string>, 'education_num': <tf.Tensor 'DecodeCSV:4' shape=(?, 1) dtype=int32>, 'marital_status': <tf.Tensor 'DecodeCSV:5' shape=(?, 1) dtype=string>, 'occupation': <tf.Tensor 'DecodeCSV:6' shape=(?, 1) dtype=string>, 'relationship': <tf.Tensor 'DecodeCSV:7' shape=(?, 1) dtype=string>, 'race': <tf.Tensor 'DecodeCSV:8' shape=(?, 1) dtype=string>, 'gender': <tf.Tensor 'DecodeCSV:9' shape=(?, 1) dtype=string>, 'capital_gain': <tf.Tensor 'DecodeCSV:10' shape=(?, 1) dtype=int32>, 'capital_loss': <tf.Tensor 'DecodeCSV:11' shape=(?, 1) dtype=int32>, 'hours_per_week': <tf.Tensor 'DecodeCSV:12' shape=(?, 1) dtype=int32>, 'native_country': <tf.Tensor 'DecodeCSV:13' shape=(?, 1) dtype=string>} Tensor(\"ToInt32:0\", shape=(?, 1), dtype=int32)\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into models/model_widendeep1544058712/model.ckpt.\n",
      "INFO:tensorflow:loss = 78.8916, step = 2\n",
      "INFO:tensorflow:global_step/sec: 44.2147\n",
      "INFO:tensorflow:loss = 1.1075586, step = 202 (3.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2623\n",
      "INFO:tensorflow:global_step/sec: 701.89\n",
      "INFO:tensorflow:loss = 36.45078, step = 402 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.44\n",
      "INFO:tensorflow:global_step/sec: 702.426\n",
      "INFO:tensorflow:loss = 3.248862e-07, step = 602 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 695.344\n",
      "INFO:tensorflow:global_step/sec: 701.05\n",
      "INFO:tensorflow:loss = 0.0047263107, step = 802 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.617\n",
      "INFO:tensorflow:global_step/sec: 679.33\n",
      "INFO:tensorflow:loss = 0.013445187, step = 1002 (0.302 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1002 into models/model_widendeep1544058712/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.013445187.\n",
      "training finish!\n"
     ]
    }
   ],
   "source": [
    "model3 = wide_n_deep_classification_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-10-08:31:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/model_linear1533889885/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-10-08:31:47\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.834125, accuracy/baseline_label_mean = 0.0, accuracy/threshold_0.500000_mean = 0.834125, auc = 1.0, auc_precision_recall = 0.0, global_step = 1000, labels/actual_label_mean = 0.0, labels/prediction_mean = 0.22233997, loss = 0.34135503, precision/positive_threshold_0.500000_mean = 0.0, recall/positive_threshold_0.500000_mean = 0.0\n",
      "{'loss': 0.34135503, 'accuracy': 0.834125, 'labels/prediction_mean': 0.22233997, 'labels/actual_label_mean': 0.0, 'accuracy/baseline_label_mean': 0.0, 'auc': 1.0, 'auc_precision_recall': 0.0, 'accuracy/threshold_0.500000_mean': 0.834125, 'precision/positive_threshold_0.500000_mean': 0.0, 'recall/positive_threshold_0.500000_mean': 0.0, 'global_step': 1000}\n",
      "Results1 Accuracy: 0.834125\n"
     ]
    }
   ],
   "source": [
    "test_dataset  = str(\"adult.test.csv\") \n",
    "\n",
    "results1 = model1.evaluate(input_fn=generate_input_fn(test_dataset), \n",
    "                     steps=200)\n",
    "print(results1)\n",
    "print('Results1 Accuracy: %s' % results1['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-10-08:31:48\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/model_deep1533889890/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-10-08:31:49\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 1.0, accuracy/baseline_label_mean = 0.0, accuracy/threshold_0.500000_mean = 1.0, auc = 1.0, auc_precision_recall = 0.0, global_step = 1000, labels/actual_label_mean = 0.0, labels/prediction_mean = 0.24562778, loss = 0.28841776, precision/positive_threshold_0.500000_mean = 0.0, recall/positive_threshold_0.500000_mean = 0.0\n",
      "{'loss': 0.28841776, 'accuracy': 1.0, 'labels/prediction_mean': 0.24562778, 'labels/actual_label_mean': 0.0, 'accuracy/baseline_label_mean': 0.0, 'auc': 1.0, 'auc_precision_recall': 0.0, 'accuracy/threshold_0.500000_mean': 1.0, 'precision/positive_threshold_0.500000_mean': 0.0, 'recall/positive_threshold_0.500000_mean': 0.0, 'global_step': 1000}\n",
      "Results2 Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_dataset  = str(\"adult.test.csv\") \n",
    "\n",
    "results2 = model2.evaluate(input_fn=generate_input_fn(test_dataset), \n",
    "                     steps=200)\n",
    "print(results2)\n",
    "print('Results2 Accuracy: %s' % results2['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-10-09:08:36\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/model_widendeep1533891699/model.ckpt-1002\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-10-09:08:38\n",
      "INFO:tensorflow:Saving dict for global step 1002: accuracy = 0.847875, accuracy/baseline_label_mean = 0.0, accuracy/threshold_0.500000_mean = 0.847875, auc = 1.0000001, auc_precision_recall = 0.0, global_step = 1002, labels/actual_label_mean = 0.0, labels/prediction_mean = 0.20990957, loss = 0.32295182, precision/positive_threshold_0.500000_mean = 0.0, recall/positive_threshold_0.500000_mean = 0.0\n",
      "{'loss': 0.32295182, 'accuracy': 0.847875, 'labels/prediction_mean': 0.20990957, 'labels/actual_label_mean': 0.0, 'accuracy/baseline_label_mean': 0.0, 'auc': 1.0000001, 'auc_precision_recall': 0.0, 'accuracy/threshold_0.500000_mean': 0.847875, 'precision/positive_threshold_0.500000_mean': 0.0, 'recall/positive_threshold_0.500000_mean': 0.0, 'global_step': 1002}\n",
      "Results3 Accuracy: 0.847875\n"
     ]
    }
   ],
   "source": [
    "test_dataset  = str(\"adult.test.csv\") \n",
    "\n",
    "results3 = model3.evaluate(input_fn=generate_input_fn(test_dataset), \n",
    "                     steps=200)\n",
    "print(results3)\n",
    "print('Results3 Accuracy: %s' % results3['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn.python.learn.utils import input_fn_utils\n",
    "\n",
    "# category type -> string, numerical type -> float32\n",
    "def column_to_dtype(column):\n",
    "    if column in CATEGORICAL_COLUMNS:\n",
    "        return tf.string\n",
    "    else:\n",
    "        return tf.float32\n",
    "\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        column: tf.placeholder(column_to_dtype(column), [None])\n",
    "        for column in FEATURE_COLUMNS\n",
    "    }\n",
    "    # DNNCombinedLinearClassifier expects rank 2 Tensors, but inputs should be\n",
    "    # rank 1, so that we can provide scalars to the server\n",
    "    features = {\n",
    "        key: tensor[:, np.newaxis] # tf.expand_dims(tensor, axis=-1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    \n",
    "    return input_fn_utils.InputFnOps(\n",
    "        features, # input into graph\n",
    "        None,\n",
    "        feature_placeholders # tensor input converted from request \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/admin_user/anaconda3/envs/gsshop/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1388: get_input_alternatives (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "WARNING:tensorflow:From /home/admin_user/anaconda3/envs/gsshop/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1402: get_output_alternatives (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "WARNING:tensorflow:From /home/admin_user/anaconda3/envs/gsshop/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1412: build_all_signature_defs (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "WARNING:tensorflow:From /home/admin_user/anaconda3/envs/gsshop/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/utils/saved_model_export_utils.py:267: build_standardized_signature_def (from tensorflow.contrib.learn.python.learn.utils.saved_model_export_utils) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Switch to tf.estimator.Exporter and associated utilities.\n",
      "INFO:tensorflow:Restoring parameters from models/model_widendeep1533891699/model.ckpt-1002\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: model_widendeep1533891699/export/temp-1533891822/saved_model.pb\n",
      "model exported successfully to b'model_widendeep1533891699/export/1533891822'\n"
     ]
    }
   ],
   "source": [
    "export_folder = model3.export_savedmodel(\n",
    "    export_dir_base = 'model_widendeep1533891699' + '/export',\n",
    "    serving_input_fn=serving_input_fn\n",
    ")\n",
    "\n",
    "print('model exported successfully to {}'.format(export_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/amygdala/tensorflow-workshop/blob/c62cfa3cd766cf0adf6d8fae7a289ae9e4ab161b/workshop_sections/wide_n_deep/wide_n_deep_flow2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
