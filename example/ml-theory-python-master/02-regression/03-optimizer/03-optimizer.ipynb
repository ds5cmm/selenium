{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Optimizer\n",
    "\n",
    "Neural network or other machine learning algorithms using optimizer for find proper weight $W$ in model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Gradient Descent\n",
    "The other way of estimate $W$ is optimization. And Gradient Descent is the basic of first-order iterative optimization.\n",
    "\n",
    "- GD(Gradient Descent) using partial derivatives of cost function.\n",
    "- Basic theorem is here. (alpha is learning rate)\n",
    "- It is important to make cost function convex.\n",
    "\n",
    "$$ \\Theta = \\Theta - \\alpha * \\frac{\\delta L}{\\delta \\Theta} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Stochastic Gradient Descent\n",
    "Gradient Descent is to slow for large dataset. Because we calculate cost for all rows in dataset. So, we should divide the dataset. It calls mini-batch.\n",
    "\n",
    "- Gradient Descent using mini-batch dataset calls SGD(Stochastic Gradient Descent).\n",
    "- It can be relatively inaccurate. But it is very fast compared to GD. \n",
    "- But there are still un-solved problems.\n",
    "    - Direction of training\n",
    "    - Step-size of training (learning rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pseudo code\n",
    "weight[i] += - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Focus on Direction of Training\n",
    "\n",
    "Optimizing method focus on direction of training.\n",
    "\n",
    "#### Momentum\n",
    "\n",
    "- Momentum means same with inertia(관성, 탄력, 가속도). \n",
    "- Update the weight referring to the previous modification direction.\n",
    "- The follow equations explain this optimizer. $ V(t) $ is momentum equation from previous state. And `m` is momentum hyper-parameter(Usually set to 0.9~0.95).\n",
    "\n",
    "$$ V(t) = m * V(t-1) - \\alpha*\\frac{\\delta Cost(W)}{\\delta W} $$\n",
    "\n",
    "$$ W(t+1) = W(t) + V(t) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pseudo code\n",
    "v = m * prev_v - learning_rate * gradient\n",
    "weight[i] += v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Focus on Step Size of Training\n",
    "\n",
    "Optimizing methods focus on direction of training.\n",
    "\n",
    "#### Adagrad(ADAptive GRADient)\n",
    "\n",
    "- Adjust learning rate(step-size, $ \\alpha $) according to each weight update step.\n",
    "- Weights that have changed with a small gradient, learning rate rises steeply. In contrast, big change in gradient, learning rate rises slowly. Because of below equation.\n",
    "\n",
    "$$ W = \\{w_1, w_2, ... w_i\\} $$\n",
    "\n",
    "$$ G_i(t) = G_i(t-1) + (\\frac{\\delta}{\\delta w_i(t)}Cost(w_i(t)))^2 $$\n",
    "\n",
    "$$ w_i(t+1) = w_i(t) - \\alpha * \\frac{1}{\\sqrt{G_i(t) + \\epsilon}} * \\frac{\\delta}{\\delta w_i} Cost(w_i)$$\n",
    "\n",
    "- For calculate each feature's learning rate($  \\alpha * \\frac{1}{\\sqrt{G_i(t) + \\epsilon}} $), we must define cost like this(Not a exact equation) : $ \\frac{1}{N}(y_i-\\hat y_i) $, instead of $ \\frac{1}{N}\\sum_{i=1}^{n} (y_i-\\hat y_i) $\n",
    "- Adagrad is very useful when each feature has different frequency in sparse dataset `(e.g. Word2Vec)`\n",
    "    - Because each word(feature)'s frequency is very different. (in Word2Vec)\n",
    "    - So, words that appeared frequently in data, learns many times than infrequent word.\n",
    "- `한글 해석 추가` : 일반적인 GD에서는 w마다 gradient는 다르지만 lr은 동일하게 적용되었음. 하지만 Adagrad는 lr도 다르게 적용됨. 이전의 모든 상태를 accumulative하게 cost에 반영하고 이는 각 스텝에서의 lr에 영향을 미치기 때문에, sparse한 데이터셋에서 빈도수가 높은 feature는 accumulative cost가 클 확률이 높고, 따라서 learning rate가 낮게끔 학습이 진행이 됨. 반대로 빈도수가 낮은 feature는 learning rate를 높게 학습함. (상식적으로 reasonable)\n",
    "----\n",
    "- $ G(t) $ means, at the time point $ t $, $ G(t) $ is sum of squares for every steps.\n",
    "\n",
    "$$ G_i(t) = G_i(t-1) + (\\frac{\\delta}{\\delta w_i(t)}Cost(w_i(t)))^2 $$\n",
    "\n",
    "$$ \\sum_{j=0}^{t} (\\frac{\\delta}{\\delta w_i(j)} Cost(w_i(j)))^2 $$\n",
    "\n",
    "- Because of this, (adagrad use accumulation of the squared gradients) it has destined to converged learning rate. But RMSProp overcome this problem.\n",
    "\n",
    "#### RMSProp \n",
    "\n",
    "- Adagrad's $ G(t) $ can be radiate to infinite. So, RMSProp using moving average.\n",
    "- RMSProp almost same with Adagrad, but using `Exponential Moving Average` (This is a method of considering weighting recently, although it is high weighted, but the old past has impact also.)\n",
    "- Sometimes $ \\gamma $ calls `decay factor`.\n",
    "\n",
    "$$ G_i(t) = \\gamma * G_i(t-1) + (1-\\gamma)*(\\frac{\\delta}{\\delta w_i(t)}Cost(w_i(t)))^2 $$\n",
    "\n",
    "$$ w_i(t+1) = w_i(t) - \\alpha * \\frac{1}{\\sqrt{G_i(t) + \\epsilon}} * \\frac{\\delta}{\\delta w_i} Cost(w_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Hybrid Method\n",
    "\n",
    "#### Adam(ADAptive Moment estimation)\n",
    "\n",
    "Hybrid method of step-size focused optimizer and direction focused optimizer.\n",
    "\n",
    "- Hybrid of Momentum and RMSProp.\n",
    "    - Proper step-size for each feature and epoch. (From RMSProp, using adaptive exponential moving average)\n",
    "    - Proper step-direction in terms of momentum or inertia (From Momentum)\n",
    "\n",
    "$$ M_i(t) = \\beta_1 * M_i(t-1) + (1-\\beta_1)*\\frac{\\delta Cost(w_i(t))}{\\delta w_i(t)} $$\n",
    "\n",
    "$$ V_i(t) = \\beta_2 * V_i(t-1) + (1-\\beta_2)(\\frac{\\delta}{\\delta w_i(t)}Cost(w_i(t)))^2 $$\n",
    "\n",
    "$$ \\hat{M_i} = \\frac{M_i(t)}{1-\\beta_1^t} $$\n",
    "\n",
    "$$ \\hat{V_i} = \\frac{V_i(t)}{1-\\beta_2^t} $$\n",
    "\n",
    "$$ w_i(t+1) = w_i(t) - \\alpha * \\frac{\\hat{M_i(t)}}{\\sqrt{\\hat{V_i(t)} + \\epsilon}}$$\n",
    "\n",
    "- And we have to use $ \\hat{M(t)} $ and $ \\hat{V(t)} $.\n",
    "    - $ M(t) $ and $ V(t) $ initialize with 0.\n",
    "    - The parameters should be biased to zero, Because we using `moving average` with start zero.\n",
    "    - So, Adam researcher correct this with $ 1-\\beta^t $.\n",
    "- These parameter were created during the process of finding the expected value ($ \\hat{M(t)} $ and $ \\hat{V(t)} $).\n",
    "- The derivation of this equation is [here](https://arxiv.org/abs/1412.6980)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### FTRL (Follow The Regularized Leader) - Proximal\n",
    "\n",
    "In large-scale binary prediction task(e.g. extreme-sparse featured logistic regression), whole-batch gradient descent is not usable. So we have to use SGD(Online batch gradient descent) algorithms like momentum, adagrad, adam, etc. But SGD like algorithms have relatively lower performance. FTRL-proximal is SOTA(State-of-the-art) algorithm like this method. FTRL-proximal's idea is based on SGD, Regularized Dual Averaging (RDA), etc.\n",
    "\n",
    "- Usually, In sparse dataset, we should use L1 regularization because of the feature selection (set as zero).\n",
    "- FTRL-proximal's equation is below.\n",
    "\n",
    "$$ w_{t+1} = argmin_w(g_{1:t}*w + \\frac{1}{2} \\sum_{s=1}^{t}\\sigma_s ||w-w_s||_2^2 + \\lambda ||w||_1 ) $$\n",
    "\n",
    "- In summary, Build a stable model that follows the trajectory of the sub-gradient, minimizes approximate losses, and prevents rapid variability of the model through regularization and proximity.\n",
    "- In generally, FTRL is just optimizer. So, sparse-problem solving predictor like FM(Factorization Machine) is better than (LR + FTRL). But FTRL can be used for FM's optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### references\n",
    "- https://seamless.tistory.com/38\n",
    "- http://incredible.ai/artificial-intelligence/2017/04/09/Optimizer-Adagrad/\n",
    "- https://twinw.tistory.com/247\n",
    "- https://arxiv.org/abs/1412.6980\n",
    "- https://brunch.co.kr/@kakao-it/84#comment\n",
    "- http://proceedings.mlr.press/v15/mcmahan11b/mcmahan11b.pdf\n",
    "- https://dos-tacos.github.io/paper%20review/FTRL/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
